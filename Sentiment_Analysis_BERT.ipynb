{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "112B9jefSUpm"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZjepUa1Sbfo"
      },
      "source": [
        "import torch\r\n",
        "from transformers import BertTokenizer,BertModel\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "l5xcaJRLSma_",
        "outputId": "b8d0eff1-ecf1-4595-8351-2215e929ad27"
      },
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1irea9QSxTB"
      },
      "source": [
        "model=BertModel.from_pretrained('bert-base-uncased',output_hidden_states=True,)\r\n",
        "model.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1XMk0awS9AN",
        "outputId": "97a0f289-18ce-44a6-d166-d4cb7c4b7d3b"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.corpus import twitter_samples\r\n",
        "nltk.download('twitter_samples')\r\n",
        "all_pos_tweets=twitter_samples.strings('positive_tweets.json')\r\n",
        "all_neg_tweets=twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43hqr9lcTAtu",
        "outputId": "685d80d3-e824-4d1c-f6a5-b4bcdfec3ed8"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "import re\r\n",
        "nltk.download('stopwords')\r\n",
        "stopwords_english=stopwords.words(\"english\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7bnOWv7TDMK"
      },
      "source": [
        "def remstop(arr):\r\n",
        "  ans=[]\r\n",
        "  for sent in arr:\r\n",
        "    temp=re.sub(\"[@#$%^&*{}_\\d+]\",\"\",sent)\r\n",
        "    temp=re.sub(r\"http\\S+\", \"\", temp)\r\n",
        "    temp=temp.split(\" \")\r\n",
        "    temp=[i+\" \" for i in temp if i not in stopwords_english]\r\n",
        "    temp=(\"\").join(temp)\r\n",
        "    ans.append(temp[:-1])\r\n",
        "  return ans"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAxk1dUZTHXA"
      },
      "source": [
        "all_pos_tweets_process=remstop(all_pos_tweets)\r\n",
        "all_neg_tweets_process=remstop(all_neg_tweets)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHq9ERV0TIgx",
        "outputId": "360f5195-4a4c-4f37-a2fd-bdb84cddc6a6"
      },
      "source": [
        "print(all_pos_tweets[20])\r\n",
        "print(all_pos_tweets_process[20])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#FollowFriday @MBandScott_ @Eric_FLE @pointsolutions3 for being top new followers in my community this week :)\n",
            "FollowFriday MBandScott EricFLE pointsolutions top new followers community week :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zoB1emdTKkU"
      },
      "source": [
        "def bertready(arr):\r\n",
        "  for i in range(len(arr)):\r\n",
        "    arr[i]=\"[CLS] \"+arr[i]+\" [SEP]\"\r\n",
        "  return arr"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GthtAFoKTNs1"
      },
      "source": [
        "all_pos_bert=bertready(all_pos_tweets_process)\r\n",
        "all_neg_bert=bertready(all_neg_tweets_process)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4q_NYlOzTRZk",
        "outputId": "69ae6da4-7709-4f23-9c92-3ab6c596ca91"
      },
      "source": [
        "all_pos_bert[30]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] MY kik - hatessuce kik kikme lgbt tinder nsfw akua cumshot :)  [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rWiPEYTWE3"
      },
      "source": [
        "def token_bert(arr):\r\n",
        "  ans=[]\r\n",
        "  for i in range(len(arr)):\r\n",
        "    temp=tokenizer.tokenize(arr[i])\r\n",
        "    if len(temp)<30:\r\n",
        "      ans.append(temp)\r\n",
        "  return ans\r\n",
        "\r\n",
        "all_pos_bert_token=token_bert(all_pos_bert)\r\n",
        "all_neg_bert_token=token_bert(all_neg_bert)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDvRJh8kTYEQ",
        "outputId": "294350df-6e98-4eb2-c4fd-a1115bd66a52"
      },
      "source": [
        "max_len=0\r\n",
        "for i in all_neg_bert_token:\r\n",
        "  max_len=max(len(i),max_len)\r\n",
        "\r\n",
        "\r\n",
        "for i in all_pos_bert_token:\r\n",
        "  max_len=max(len(i),max_len)\r\n",
        "\r\n",
        "print(max_len)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1QK14nXTaj2"
      },
      "source": [
        "def convert(arr):\r\n",
        "  tok=[]\r\n",
        "  seg=[]\r\n",
        "  for token in arr:\r\n",
        "    seg.append([1]*len(token)+[0]*(max_len-len(token)))\r\n",
        "    tok.append(token+[\"[PAD]\"]*(max_len-len(token)))\r\n",
        "  return tok,seg\r\n",
        "\r\n",
        "all_neg_bert_token_padded,segment_neg=convert(all_neg_bert_token)\r\n",
        "all_pos_bert_token_padded,segment_pos=convert(all_pos_bert_token)\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ8nxnhiTcgr"
      },
      "source": [
        "train_pos=all_pos_bert_token_padded[:2000]\r\n",
        "train_neg=all_neg_bert_token_padded[:2000]\r\n",
        "test_pos=all_pos_bert_token_padded[4000:]\r\n",
        "test_neg=all_neg_bert_token_padded[4000:]\r\n",
        "\r\n",
        "segment_pos_train=segment_pos[:2000]\r\n",
        "segment_neg_train=segment_neg[:2000]\r\n",
        "segment_pos_test=segment_pos[4000:]\r\n",
        "segment_neg_test=segment_neg[4000:]\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUtEUHuvThMj"
      },
      "source": [
        "label=[0]*2000+[1]*2000\r\n",
        "train_data=train_pos+train_neg"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WzrgVaUTnOr"
      },
      "source": [
        "import numpy as np\r\n",
        "train_data_stack=np.vstack(train_data)\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j88SOQmGTklb",
        "outputId": "fa6c000f-6b27-4728-d330-f064198c2826"
      },
      "source": [
        "label_stack=np.vstack(label)\r\n",
        "label_stack.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euDh7sn8TpX_"
      },
      "source": [
        "seg_train=segment_pos_train+segment_neg_train"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD7IATYbTsZM"
      },
      "source": [
        "segment_stack=np.vstack(seg_train)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxdbgzdUTuV3"
      },
      "source": [
        "indexed_tokens=[tokenizer.convert_tokens_to_ids(i) for i in train_data]\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxBvRxQuTv7G"
      },
      "source": [
        "indexed_tokens_stack=np.vstack(indexed_tokens)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Ag7ubGTyF-"
      },
      "source": [
        "tokens_tensor=torch.tensor(indexed_tokens_stack,device=device)\r\n",
        "segment_tensor=torch.tensor(segment_stack,device=device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8rJR-8YT7Mt"
      },
      "source": [
        "with torch.no_grad():\r\n",
        "  outputs=model(tokens_tensor,segment_tensor)\r\n",
        "  hidden_states=outputs[2]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWQ9sduBT9CN",
        "outputId": "e0440512-328c-41c1-cb5a-9383745ad02b"
      },
      "source": [
        "hidden_states[0].shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4000, 29, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mInkDda-UAUO"
      },
      "source": [
        "import torch.nn as nn\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cchxbK3WUazW",
        "outputId": "9257e9a1-c5ef-4e61-fffc-959f99b884e3"
      },
      "source": [
        "class SentimentLSTM(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.lstm1=nn.LSTM(768,128,32,dropout=0.3,batch_first=True)\r\n",
        "    self.dropout=nn.Dropout(0.3)\r\n",
        "    self.fc1=nn.Linear(128,64)\r\n",
        "    self.fc2=nn.Linear(64,32)\r\n",
        "    self.fc3=nn.Linear(32,1)\r\n",
        "    self.relu=nn.ReLU()\r\n",
        "    self.sigmoid=nn.Sigmoid()\r\n",
        "  \r\n",
        "  def forward(self,x,hidden,carry):\r\n",
        "    batch_size=x.size(0)\r\n",
        "    lstm_out,(hidden,carry)=self.lstm1(x,(hidden,carry))\r\n",
        "    out=self.fc1(lstm_out[:,1,:])\r\n",
        "    \r\n",
        "    out=self.relu(out)\r\n",
        "    out=self.fc2(out)\r\n",
        "    out=self.relu(out)\r\n",
        "    out=self.fc3(out)\r\n",
        "    out=self.sigmoid(out)\r\n",
        "    print(out.size())\r\n",
        "    return out,hidden,carry\r\n",
        "\r\n",
        "  def init_hidden(self,batch_size):\r\n",
        "    weight = next(self.parameters()).data\r\n",
        "    \r\n",
        "    hidden = weight.new(32, batch_size, 128).zero_().cuda()\r\n",
        "    carry=weight.new(32, batch_size,128).zero_().cuda()\r\n",
        "    return hidden,carry\r\n",
        "model_sent=SentimentLSTM()\r\n",
        "print(model_sent)\r\n",
        "model_sent.to(device)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (lstm1): LSTM(768, 128, num_layers=32, batch_first=True, dropout=0.3)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentLSTM(\n",
              "  (lstm1): LSTM(768, 128, num_layers=32, batch_first=True, dropout=0.3)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jE2bSK7W9VF"
      },
      "source": [
        "rnn = nn.LSTM(768, 128, 5)\r\n",
        "input = torch.randn(5, 3, 768)\r\n",
        "h0 = torch.randn(5, 3, 128)\r\n",
        "c0 = torch.randn(5, 3, 128)\r\n",
        "output, (hn, cn) = rnn(input, (h0, c0))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fEzUaxEXCE4"
      },
      "source": [
        "train_data=hidden_states[0]\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxXXgulcfiqs"
      },
      "source": [
        "label_train=torch.tensor(label_stack,device=device)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foxbTrm5ftM5",
        "outputId": "492bb05e-b2a3-4855-bd3d-60933badd2cc"
      },
      "source": [
        "model_sent=SentimentLSTM()\r\n",
        "print(model_sent)\r\n",
        "model_sent.to(device)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (lstm1): LSTM(768, 128, num_layers=32, batch_first=True, dropout=0.3)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentLSTM(\n",
              "  (lstm1): LSTM(768, 128, num_layers=32, batch_first=True, dropout=0.3)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8gdcr-di_Sa",
        "outputId": "ee548e90-5065-49fa-cf9f-d9a70d6930cf"
      },
      "source": [
        "label.size()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJTTVW7iIiV"
      },
      "source": [
        "from torch.utils.data import DataLoader,TensorDataset"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yls1P7QHk-pX"
      },
      "source": [
        "train_data_arr=train_data.cpu().detach().numpy()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLUolT9oqt54"
      },
      "source": [
        "label_train_arr=label_train.cpu().detach().numpy()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuBM-d5jk_MT",
        "outputId": "db664943-7e8c-4a6d-98aa-277059e27a96"
      },
      "source": [
        "train_data_arr.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 29, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwUA3ra9k-b0",
        "outputId": "95c8e447-cd47-4333-ea90-4616f7edbcd9"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4000, 29, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7niHr3p9iTm1"
      },
      "source": [
        "train_load = TensorDataset(torch.from_numpy(train_data_arr),torch.from_numpy(label_train_arr))\r\n",
        "train_loader=DataLoader(train_load,shuffle=True,batch_size=16)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCbw0Cdhi0xe"
      },
      "source": [
        "dataiter = iter(train_loader)\r\n",
        "sample_x, sample_y = dataiter.next()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1S91v09s6-Z",
        "outputId": "f1dab579-bb57-4765-ed14-35fd95013c6d"
      },
      "source": [
        "class SentimentLSTM(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.lstm1=nn.LSTM(768,128,32,dropout=0.3,batch_first=True)\r\n",
        "    self.dropout=nn.Dropout(0.3)\r\n",
        "    self.fc1=nn.Linear(128,64)\r\n",
        "    self.fc2=nn.Linear(64,32)\r\n",
        "    self.fc3=nn.Linear(32,1)\r\n",
        "    self.relu1=nn.ReLU()\r\n",
        "    self.relu2=nn.ReLU()\r\n",
        "    self.sigmoid=nn.Sigmoid()\r\n",
        "  \r\n",
        "  def forward(self,x,hidden,carry):\r\n",
        "    batch_size=x.size(0)\r\n",
        "    lstm_out,(hidden,carry)=self.lstm1(x,(hidden,carry))\r\n",
        "    out=self.fc1(lstm_out[:,1,:])\r\n",
        "    # print(out.size())\r\n",
        "    out=self.relu1(out)\r\n",
        "    out=self.fc2(out)\r\n",
        "    out=self.relu2(out)\r\n",
        "    out=self.fc3(out)\r\n",
        "    out=self.sigmoid(out)\r\n",
        "    # print(out.size())\r\n",
        "    return out,hidden,carry\r\n",
        "\r\n",
        "  def init_hidden(self,batch_size):\r\n",
        "    weight = next(self.parameters()).data\r\n",
        "    \r\n",
        "    hidden = weight.new(32, batch_size, 128).zero_().cuda()\r\n",
        "    carry=weight.new(32, batch_size,128).zero_().cuda()\r\n",
        "    return hidden,carry\r\n",
        "model_sent=SentimentLSTM()\r\n",
        "print(model_sent)\r\n",
        "model_sent.to(device)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (lstm1): LSTM(768, 128, num_layers=32, batch_first=True, dropout=0.3)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentLSTM(\n",
              "  (lstm1): LSTM(768, 128, num_layers=32, batch_first=True, dropout=0.3)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (relu2): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "R18JlTalgIxn",
        "outputId": "0ad75de9-9316-4a7e-8bab-ea2d87d252f7"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\r\n",
        "lr=0.01\r\n",
        "criterion=nn.BCELoss()\r\n",
        "optimizer=torch.optim.Adam(model_sent.parameters(),lr=lr)\r\n",
        "epoch=4\r\n",
        "model_sent.train()\r\n",
        "counter=0\r\n",
        "\r\n",
        "for i in range(epoch):\r\n",
        "  h,c=model_sent.init_hidden(16)\r\n",
        "  for inputs,labels in train_loader:\r\n",
        "    counter+=1\r\n",
        "    inputs=inputs.cuda()\r\n",
        "    labels=labels.cuda()\r\n",
        "    model_sent.zero_grad()\r\n",
        "    output,h,c=model_sent(inputs,h,c)\r\n",
        "    loss=criterion(output.squeeze(),labels.float().squeeze())\r\n",
        "    loss.backward(retain_graph=True)\r\n",
        "    nn.utils.clip_grad_norm_(model_sent.parameters(), 5)\r\n",
        "    optimizer.step()\r\n",
        "    print(\"Epoch: {}/{}...\".format(i+1, epoch),\r\n",
        "                  \"Step: {}...\".format(counter),\r\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4... Step: 1... Loss: 0.749441...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-3824f34b92cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 768]] is at version 5; expected version 4 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMoe2rpqr3mv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}